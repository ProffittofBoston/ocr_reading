{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6f8fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract as py\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b73f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_1 = 'test_image.png'\n",
    "image_2 = 'test_image_2.png'\n",
    "image_3 = 'test_image_4.png'\n",
    "image_4 = 'test_image_3.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa6f8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inches_to_pixels(inches, dpi=300):\n",
    "    return int(inches * dpi)\n",
    "\n",
    "# Example usage:\n",
    "left = inches_to_pixels(0.25)\n",
    "top = inches_to_pixels(2)\n",
    "width = inches_to_pixels(3)\n",
    "height = inches_to_pixels(0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1117fb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"left\": 408, \"top\":175, \"width\": 170, \"height\": 36}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63014d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pdf2image import convert_from_path\n",
    "# from PIL import Image, ImageDraw\n",
    "# import pytesseract\n",
    "\n",
    "# Convert PDF to image (first page as an example)\n",
    "# images = convert_from_path('your_pdf_file.pdf', dpi=300)  # Higher DPI for better accuracy\n",
    "images = convert_from_path('Signed_TestFraudAffidavit.pdf', dpi=300)\n",
    "image = images[0]  # Selecting the first page\n",
    "\n",
    "# Define the coordinates for the bounding box (in points, where 1 inch = 72 points)\n",
    "dpi = 300  # Ensure DPI is correct for conversion\n",
    "left_points = 408  # 0.25 inches = 18 points (0.25 * 72)\n",
    "top_points = 175  # 2 inches = 144 points (2 * 72)\n",
    "width_points = 170  # 3 inches = 216 points (3 * 72)\n",
    "height_points = 36  # 3 inches = 216 points (3 * 72)\n",
    "\n",
    "# Convert points to pixels using the DPI\n",
    "left = (left_points / 72) * dpi\n",
    "top = (top_points / 72) * dpi\n",
    "width = (width_points / 72) * dpi\n",
    "height = (height_points / 72) * dpi\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Draw the bounding box on the original image\n",
    "draw = ImageDraw.Draw(image)\n",
    "draw.rectangle([left, top, left + width, top + height], outline=\"red\", width=2)\n",
    "\n",
    "# Display the image with the bounding box\n",
    "image.show()\n",
    "\n",
    "# Crop the region and perform OCR\n",
    "cropped_region = image.crop((left, top, left + width, top + height))\n",
    "text = py.image_to_string(cropped_region)\n",
    "\n",
    "# # Output the extracted text\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967de0ed",
   "metadata": {},
   "source": [
    "### Section 2 Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc8acdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "from PIL import Image, ImageDraw\n",
    "import pytesseract\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Helper function to convert points to pixels using DPI\n",
    "def points_to_pixels(points, dpi=300):\n",
    "    return (points / 72) * dpi\n",
    "\n",
    "# Step 1: Convert the first page of the PDF to an image\n",
    "images = convert_from_path('Signed_TestFraudAffidavit.pdf', dpi=300, first_page=1, last_page=1)\n",
    "image = images[0]  # Use the first page\n",
    "\n",
    "# Step 2: Define the bounding box in points (original measurements)\n",
    "left_points = 38      # Left boundary in points\n",
    "top_points = 137      # Top boundary in points\n",
    "width_points = 370    # Width of the bounding box in points\n",
    "height_points = 38    # Height of the bounding box in points\n",
    "\n",
    "# Step 3: Convert points to pixels using the DPI\n",
    "left = points_to_pixels(left_points)\n",
    "top = points_to_pixels(top_points)\n",
    "width = points_to_pixels(width_points)\n",
    "height = points_to_pixels(height_points)\n",
    "\n",
    "# Step 4: Draw the bounding box on the image (for visualization)\n",
    "draw = ImageDraw.Draw(image)\n",
    "draw.rectangle([left, top, left + width, top + height], outline=\"red\", width=2)\n",
    "image.show()  # Display the image with the bounding box\n",
    "\n",
    "# Step 5: Crop the region of interest\n",
    "cropped_region = image.crop((left, top, left + width, top + height))\n",
    "\n",
    "# Step 6: Preprocess the cropped image for better OCR accuracy\n",
    "# Convert to a NumPy array and grayscale\n",
    "cropped_image_np = np.array(cropped_region)\n",
    "gray = cv2.cvtColor(cropped_image_np, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply binary thresholding for enhanced contrast\n",
    "_, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Convert back to a PIL image for pytesseract\n",
    "preprocessed_image = Image.fromarray(thresh)\n",
    "\n",
    "# Step 7: Perform OCR on the preprocessed image\n",
    "text = pytesseract.image_to_string(preprocessed_image)\n",
    "\n",
    "# Step 8: Output the extracted text\n",
    "print(\"Extracted Text:\")\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b693729e",
   "metadata": {},
   "source": [
    "### Section 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f0adc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "from PIL import Image, ImageDraw\n",
    "import pytesseract\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Helper function to convert points to pixels using DPI\n",
    "def points_to_pixels(points, dpi=300):\n",
    "    return (points / 72) * dpi\n",
    "\n",
    "# Step 1: Convert all pages of the PDF to images\n",
    "images = convert_from_path('Signed_TestFraudAffidavit.pdf', dpi=300)\n",
    "\n",
    "# Step 2: Define multiple bounding boxes in points (coordinates for each box)\n",
    "bounding_boxes = [\n",
    "    {\"left\": 38, \"top\": 137, \"width\": 370, \"height\": 38},   # Box 1\n",
    "    {\"left\": 38, \"top\": 200, \"width\": 370, \"height\": 38},   # Box 2\n",
    "    # Add more boxes as needed\n",
    "]\n",
    "\n",
    "# Step 3: Loop through each page and process all bounding boxes\n",
    "for page_num, image in enumerate(images, start=1):\n",
    "    print(f\"Processing page {page_num}...\")\n",
    "    \n",
    "    # Draw all bounding boxes on the page (for visualization)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    for box in bounding_boxes:\n",
    "        # Convert points to pixels\n",
    "        left = points_to_pixels(box[\"left\"])\n",
    "        top = points_to_pixels(box[\"top\"])\n",
    "        width = points_to_pixels(box[\"width\"])\n",
    "        height = points_to_pixels(box[\"height\"])\n",
    "\n",
    "        # Draw the bounding box\n",
    "        draw.rectangle([left, top, left + width, top + height], outline=\"red\", width=2)\n",
    "        \n",
    "        # Step 4: Crop the region of interest\n",
    "        cropped_region = image.crop((left, top, left + width, top + height))\n",
    "\n",
    "        # Step 5: Preprocess the cropped image for better OCR accuracy\n",
    "        cropped_image_np = np.array(cropped_region)\n",
    "        gray = cv2.cvtColor(cropped_image_np, cv2.COLOR_BGR2GRAY)\n",
    "        _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
    "        preprocessed_image = Image.fromarray(thresh)\n",
    "\n",
    "        # Step 6: Perform OCR on the preprocessed image\n",
    "        text = pytesseract.image_to_string(preprocessed_image)\n",
    "\n",
    "        # Step 7: Output the extracted text\n",
    "        print(f\"Text from box ({box['left']}, {box['top']}):\")\n",
    "        print(text)\n",
    "\n",
    "    # Optional: Show the page with all boxes drawn\n",
    "    image.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30121b4d",
   "metadata": {},
   "source": [
    "### Section 4 - Best Used Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c6e6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "from PIL import Image, ImageDraw\n",
    "import pytesseract\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Helper function to convert points to pixels using DPI\n",
    "def points_to_pixels(points, dpi=300):\n",
    "    return (points / 72) * dpi\n",
    "\n",
    "# Step 1: Convert all pages of the PDF to images\n",
    "images = convert_from_path('Signed_TestFraudAffidavit.pdf', dpi=300)\n",
    "\n",
    "# Step 2: Define page-specific bounding boxes (coordinates in points)\n",
    "page_boundaries = {\n",
    "    1: [  # Page 1 boundaries\n",
    "        {\"left\": 38, \"top\": 137, \"width\": 370, \"height\": 38},   # Customer Names\n",
    "        {\"left\": 408, \"top\": 137, \"width\": 170, \"height\": 38},    # Account Number\n",
    "        {\"left\": 38, \"top\":175, \"width\": 370, \"height\": 36}, #Business Name\n",
    "        {\"left\": 408, \"top\":175, \"width\": 170, \"height\": 36} #Phone Number\n",
    "    ],\n",
    "    2: [  # Page 2 boundaries\n",
    "        {\"left\": 50, \"top\": 150, \"width\": 300, \"height\": 40},   # Box 1 for page 2\n",
    "        {\"left\": 50, \"top\": 220, \"width\": 300, \"height\": 40}    # Box 2 for page 2\n",
    "    ]\n",
    "    # Add more pages and boundaries as needed\n",
    "}\n",
    "\n",
    "# Step 3: Loop through each page and process its respective bounding boxes\n",
    "for page_num, image in enumerate(images, start=1):\n",
    "    print(f\"Processing page {page_num}...\")\n",
    "\n",
    "    # Get the bounding boxes for the current page\n",
    "    bounding_boxes = page_boundaries.get(page_num, [])\n",
    "\n",
    "    # Draw and process each bounding box\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    for box in bounding_boxes:\n",
    "        # Convert points to pixels\n",
    "        left = points_to_pixels(box[\"left\"])\n",
    "        top = points_to_pixels(box[\"top\"])\n",
    "        width = points_to_pixels(box[\"width\"])\n",
    "        height = points_to_pixels(box[\"height\"])\n",
    "\n",
    "        # Draw the bounding box for visualization\n",
    "        draw.rectangle([left, top, left + width, top + height], outline=\"red\", width=2)\n",
    "\n",
    "        # Step 4: Crop the region of interest\n",
    "        cropped_region = image.crop((left, top, left + width, top + height))\n",
    "\n",
    "        # Step 5: Preprocess the cropped image for better OCR accuracy\n",
    "        cropped_image_np = np.array(cropped_region)\n",
    "        gray = cv2.cvtColor(cropped_image_np, cv2.COLOR_BGR2GRAY)\n",
    "        _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
    "        preprocessed_image = Image.fromarray(thresh)\n",
    "\n",
    "        # Step 6: Perform OCR on the preprocessed image\n",
    "        text = pytesseract.image_to_string(preprocessed_image)\n",
    "\n",
    "        # Step 7: Output the extracted text\n",
    "        print(f\"Text from box ({box['left']}, {box['top']}) on page {page_num}:\")\n",
    "        print(text)\n",
    "\n",
    "    # Optional: Show the page with all boxes drawn\n",
    "    image.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27471fd5",
   "metadata": {},
   "source": [
    "### Section 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "196dece5",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (667761284.py, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 17\u001b[1;36m\u001b[0m\n\u001b[1;33m    1: {\"left\": 38, \"top\": 110, \"width\": 540, \"height\": 225},  # Covers all fields for page 1\u001b[0m\n\u001b[1;37m     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from pdf2image import convert_from_path\n",
    "from PIL import Image, ImageDraw\n",
    "import pytesseract\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Helper function to convert points to pixels using DPI\n",
    "def points_to_pixels(points, dpi=300):\n",
    "    return (points / 72) * dpi\n",
    "\n",
    "# Step 1: Convert all pages of the PDF to images\n",
    "images = convert_from_path('Signed_TestFraudAffidavit.pdf', dpi=300)\n",
    "\n",
    "#Establish initial page boundaries\n",
    "initial_boundaries = {\n",
    "    1: {\"left\": 38, \"top\": 110, \"width\": 540, \"height\": 225},  # Covers all fields for page 1\n",
    "    2: {\"left\": 50, \"top\": 140, \"width\": 500, \"height\": 200}   # Example boundary for page 2\n",
    "}\n",
    "\n",
    "# Step 2: Define page-specific bounding boxes (coordinates in points)\n",
    "# page_boundaries = {\n",
    "#     1: [  # Page 1 boundaries\n",
    "#         {\"left\": 38, \"top\": 137, \"width\": 370, \"height\": 38},   # Customer Names\n",
    "#         {\"left\": 408, \"top\": 137, \"width\": 170, \"height\": 38},    # Account Number\n",
    "#         {\"left\": 38, \"top\":175, \"width\": 370, \"height\": 36}, #Business Name\n",
    "#         {\"left\": 408, \"top\":175, \"width\": 170, \"height\": 36} #Phone Number\n",
    "#     ],\n",
    "#     2: [  # Page 2 boundaries\n",
    "#         {\"left\": 50, \"top\": 150, \"width\": 300, \"height\": 40},   # Box 1 for page 2\n",
    "#         {\"left\": 50, \"top\": 220, \"width\": 300, \"height\": 40}    # Box 2 for page 2\n",
    "#     ]\n",
    "#     # Add more pages and boundaries as needed\n",
    "# }\n",
    "\n",
    "# Step 3: Loop through each page and process its respective bounding boxes\n",
    "for page_num, image in enumerate(images, start=1):\n",
    "    print(f\"Processing page {page_num}...\")\n",
    "\n",
    "    # Get the bounding boxes for the current page\n",
    "    bounding_boxes = initial_boundaries.get(page_num, [])\n",
    "\n",
    "    # Draw and process each bounding box\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    for box in bounding_boxes:\n",
    "        # Convert points to pixels\n",
    "        left = points_to_pixels(box[\"left\"])\n",
    "        top = points_to_pixels(box[\"top\"])\n",
    "        width = points_to_pixels(box[\"width\"])\n",
    "        height = points_to_pixels(box[\"height\"])\n",
    "\n",
    "        # Draw the bounding box for visualization\n",
    "        draw.rectangle([left, top, left + width, top + height], outline=\"red\", width=2)\n",
    "\n",
    "        # Step 4: Crop the region of interest\n",
    "        cropped_region = image.crop((left, top, left + width, top + height))\n",
    "\n",
    "        # Step 5: Preprocess the cropped image for better OCR accuracy\n",
    "        cropped_image_np = np.array(cropped_region)\n",
    "        gray = cv2.cvtColor(cropped_image_np, cv2.COLOR_BGR2GRAY)\n",
    "        _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
    "        preprocessed_image = Image.fromarray(thresh)\n",
    "\n",
    "        # Step 6: Perform OCR on the preprocessed image\n",
    "        text = pytesseract.image_to_string(preprocessed_image)\n",
    "\n",
    "        # Step 7: Output the extracted text\n",
    "        print(f\"Text from box ({box['left']}, {box['top']}) on page {page_num}:\")\n",
    "        print(text)\n",
    "\n",
    "    # Optional: Show the page with all boxes drawn\n",
    "    image.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876005d0",
   "metadata": {},
   "source": [
    "### Section 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7ce1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "from PIL import Image, ImageDraw\n",
    "import pytesseract\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Helper function to convert points to pixels using DPI\n",
    "def points_to_pixels(points, dpi=300):\n",
    "    return (points / 72) * dpi\n",
    "\n",
    "# Step 1: Convert all pages of the PDF to images\n",
    "images = convert_from_path('Signed_TestFraudAffidavit.pdf', dpi=300)\n",
    "\n",
    "# Step 2: Define page-specific bounding boxes with their respective target strings\n",
    "page_boundaries = {\n",
    "    1: [  # Page 1 boundaries\n",
    "        {\"left\": 38, \"top\": 137, \"width\": 370, \"height\": 38, \"target\": \"Customer Name(s)\"},   # Box 1\n",
    "        {\"left\": 408, \"top\": 137, \"width\": 170, \"height\": 38, \"target\": \"Account Number\"}    # Box 2\n",
    "    ],\n",
    "    2: [  # Page 2 boundaries\n",
    "        {\"left\": 50, \"top\": 150, \"width\": 300, \"height\": 40, \"target\": \"Date of Transaction\"},   # Box 1 for page 2\n",
    "        {\"left\": 50, \"top\": 220, \"width\": 300, \"height\": 40, \"target\": \"Transaction Amount\"}    # Box 2 for page 2\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Step 3: Loop through each page and process its respective bounding boxes\n",
    "for page_num, image in enumerate(images, start=1):\n",
    "    print(f\"Processing page {page_num}...\")\n",
    "\n",
    "    # Get the bounding boxes for the current page\n",
    "    bounding_boxes = page_boundaries.get(page_num, [])\n",
    "\n",
    "    # Draw and process each bounding box\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    for box in bounding_boxes:\n",
    "        # Convert points to pixels\n",
    "        left = points_to_pixels(box[\"left\"])\n",
    "        top = points_to_pixels(box[\"top\"])\n",
    "        width = points_to_pixels(box[\"width\"])\n",
    "        height = points_to_pixels(box[\"height\"])\n",
    "        target_string = box[\"target\"]\n",
    "\n",
    "        # Draw the bounding box for visualization\n",
    "        draw.rectangle([left, top, left + width, top + height], outline=\"red\", width=2)\n",
    "\n",
    "        # Step 4: Crop the region of interest\n",
    "        cropped_region = image.crop((left, top, left + width, top + height))\n",
    "\n",
    "        # Step 5: Preprocess the cropped image for better OCR accuracy\n",
    "        cropped_image_np = np.array(cropped_region)\n",
    "        gray = cv2.cvtColor(cropped_image_np, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Try adaptive thresholding to handle different lighting conditions\n",
    "        thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                      cv2.THRESH_BINARY, 11, 2)\n",
    "        \n",
    "        # Optionally, perform a slight dilation to connect characters better\n",
    "        kernel = np.ones((1, 1), np.uint8)\n",
    "        processed_image = cv2.dilate(thresh, kernel, iterations=1)\n",
    "\n",
    "        preprocessed_image = Image.fromarray(processed_image)\n",
    "\n",
    "        # Step 6: Perform OCR on the preprocessed image\n",
    "        ocr_data = pytesseract.image_to_data(preprocessed_image, output_type=pytesseract.Output.DICT)\n",
    "\n",
    "        # Print OCR results for debugging\n",
    "        print(f\"OCR Text for box '{target_string}' on page {page_num}:\")\n",
    "        for word in ocr_data[\"text\"]:\n",
    "            print(word)\n",
    "\n",
    "        # Step 7: Search for the target string within the OCR data\n",
    "        found = False\n",
    "        for i, word in enumerate(ocr_data[\"text\"]):\n",
    "            if target_string.lower() in word.lower():\n",
    "                found = True\n",
    "                # Get the bounding box for the matched string\n",
    "                left = ocr_data[\"left\"][i]\n",
    "                top = ocr_data[\"top\"][i]\n",
    "                width = ocr_data[\"width\"][i]\n",
    "                height = ocr_data[\"height\"][i]\n",
    "\n",
    "                # Draw a rectangle around the matched string\n",
    "                draw.rectangle([left, top, left + width, top + height], outline=\"blue\", width=2)\n",
    "\n",
    "                # Output the extracted text for verification\n",
    "                cropped_region = image.crop((left, top, left + width, top + height))\n",
    "                cropped_text = pytesseract.image_to_string(cropped_region)\n",
    "                print(f\"Found '{target_string}' at ({left}, {top}) on page {page_num}:\")\n",
    "                print(cropped_text)\n",
    "                break\n",
    "\n",
    "        if not found:\n",
    "            print(f\"'{target_string}' not found on page {page_num}\")\n",
    "\n",
    "    # Optional: Show the page with all boxes drawn\n",
    "    image.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064ed05b",
   "metadata": {},
   "source": [
    "### Section 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb0d9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "from PIL import Image, ImageDraw\n",
    "import pytesseract\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Helper function to convert points to pixels using DPI\n",
    "def points_to_pixels(points, dpi=300):\n",
    "    return (points / 72) * dpi\n",
    "\n",
    "# Step 1: Convert all pages of the PDF to images\n",
    "images = convert_from_path('Signed_TestFraudAffidavit.pdf', dpi=300)\n",
    "\n",
    "# Step 2: Define page-specific larger boundary boxes (coordinates in points) to encompass all sub-boundaries\n",
    "initial_boundaries = {\n",
    "    1: {\"left\": 38, \"top\": 130, \"width\": 540, \"height\": 100},  # Covers all fields for page 1\n",
    "    2: {\"left\": 50, \"top\": 140, \"width\": 500, \"height\": 200}   # Example boundary for page 2\n",
    "}\n",
    "\n",
    "# Step 3: Define target strings for each page and their respective field names\n",
    "target_strings = {\n",
    "    1: {\n",
    "        \"Account Holder(s)\": \"customer_name\",\n",
    "        \"Account Number\": \"account_number\",\n",
    "        \"Business Name (if applicable)\": \"business_name\",\n",
    "        \"Phone Number\": \"phone_number\"\n",
    "    },\n",
    "    2: {\n",
    "        \"Date of Transaction\": \"date_of_transaction\",\n",
    "        \"Transaction Amount\": \"transaction_amount\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Step 4: Loop through each page and process its respective larger boundary\n",
    "for page_num, image in enumerate(images, start=1):\n",
    "    print(f\"Processing page {page_num}...\")\n",
    "\n",
    "    # Get the larger boundary for the current page\n",
    "    boundary = initial_boundaries.get(page_num)\n",
    "    if not boundary:\n",
    "        continue\n",
    "\n",
    "    # Convert points to pixels\n",
    "    left = points_to_pixels(boundary[\"left\"])\n",
    "    top = points_to_pixels(boundary[\"top\"])\n",
    "    width = points_to_pixels(boundary[\"width\"])\n",
    "    height = points_to_pixels(boundary[\"height\"])\n",
    "\n",
    "    # Draw the larger bounding box for visualization\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    draw.rectangle([left, top, left + width, top + height], outline=\"blue\", width=2)\n",
    "\n",
    "    # Step 5: Crop the larger region of interest\n",
    "    cropped_region = image.crop((left, top, left + width, top + height))\n",
    "\n",
    "    # Step 6: Preprocess the cropped image for better OCR accuracy\n",
    "    cropped_image_np = np.array(cropped_region)\n",
    "    gray = cv2.cvtColor(cropped_image_np, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
    "    preprocessed_image = Image.fromarray(thresh)\n",
    "\n",
    "    # Step 7: Perform OCR on the preprocessed image\n",
    "    ocr_text = pytesseract.image_to_string(preprocessed_image)\n",
    "\n",
    "    # Step 8: Search for each target string and extract the text to its right\n",
    "    page_targets = target_strings.get(page_num, {})\n",
    "    for target, field_name in page_targets.items():\n",
    "        print(f\"Searching for '{target}'...\")\n",
    "\n",
    "        # Find the position of the target string\n",
    "        target_pos = ocr_text.find(target)\n",
    "        if target_pos != -1:\n",
    "            # Extract the text to the right of the target string\n",
    "            extracted_text = ocr_text[target_pos + len(target):].split(\"\\n\")[0].strip()\n",
    "            print(f\"Extracted '{field_name}': {extracted_text}\")\n",
    "        else:\n",
    "            print(f\"'{target}' not found on page {page_num}\")\n",
    "\n",
    "    # Optional: Show the page with the larger boundary drawn\n",
    "    image.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa7f9bf",
   "metadata": {},
   "source": [
    "### Section 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7f7a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "from PIL import Image, ImageDraw\n",
    "import pytesseract\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Helper function to convert points to pixels using DPI\n",
    "def points_to_pixels(points, dpi=300):\n",
    "    return (points / 72) * dpi\n",
    "\n",
    "# Step 1: Convert all pages of the PDF to images\n",
    "images = convert_from_path('Signed_TestFraudAffidavit.pdf', dpi=300)\n",
    "\n",
    "# Step 2: Define page-specific larger boundary boxes (coordinates in points) to encompass all sub-boundaries\n",
    "initial_boundaries = {\n",
    "    1: {\"left\": 38, \"top\": 130, \"width\": 540, \"height\": 225},  # Covers all fields for page 1\n",
    "    2: {\"left\": 50, \"top\": 140, \"width\": 500, \"height\": 200}   # Example boundary for page 2\n",
    "}\n",
    "\n",
    "# Step 3: Define target strings for each page and their respective field names\n",
    "target_strings = {\n",
    "    1: {\n",
    "        \"Account Holder(s)\": \"customer_name\",\n",
    "        \"Account Number\": \"account_number\",\n",
    "        \"Business Name\": \"business_name\",\n",
    "        \"Phone Number\": \"phone_number\",\n",
    "        \"Address\": \"address_line\",\n",
    "        \"City\": \"city_line\",\n",
    "        \"State\": \"state_line\",\n",
    "        \"Zip\":\"zip_line\",\n",
    "        \"Was a police report filed?\": \"report_radio_buttons\",\n",
    "        \"Name of Law Enforcement Agency\": \"law_enforcement_agency\",\n",
    "        \"Report Number\":\"report_number\"\n",
    "        \n",
    "    },\n",
    "    2: {\n",
    "        \"Date of Transaction\": \"date_of_transaction\",\n",
    "        \"Transaction Amount\": \"transaction_amount\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Step 4: Loop through each page and process its respective larger boundary\n",
    "for page_num, image in enumerate(images, start=1):\n",
    "    print(f\"Processing page {page_num}...\")\n",
    "\n",
    "    # Get the larger boundary for the current page\n",
    "    boundary = initial_boundaries.get(page_num)\n",
    "    if not boundary:\n",
    "        continue\n",
    "\n",
    "    # Convert points to pixels\n",
    "    left = points_to_pixels(boundary[\"left\"])\n",
    "    top = points_to_pixels(boundary[\"top\"])\n",
    "    width = points_to_pixels(boundary[\"width\"])\n",
    "    height = points_to_pixels(boundary[\"height\"])\n",
    "\n",
    "    # Draw the larger bounding box for visualization\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    draw.rectangle([left, top, left + width, top + height], outline=\"blue\", width=2)\n",
    "\n",
    "    # Step 5: Crop the larger region of interest\n",
    "    cropped_region = image.crop((left, top, left + width, top + height))\n",
    "\n",
    "    # Step 6: Preprocess the cropped image for better OCR accuracy\n",
    "    cropped_image_np = np.array(cropped_region)\n",
    "    gray = cv2.cvtColor(cropped_image_np, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
    "    preprocessed_image = Image.fromarray(thresh)\n",
    "\n",
    "    # Step 7: Perform OCR on the preprocessed image\n",
    "    ocr_text = pytesseract.image_to_string(preprocessed_image)\n",
    "\n",
    "    # Step 8: Search for each target string and extract the text to its right or on the next line\n",
    "    page_targets = target_strings.get(page_num, {})\n",
    "    for target, field_name in page_targets.items():\n",
    "        print(f\"Searching for '{target}'...\")\n",
    "\n",
    "        # Find the position of the target string\n",
    "        target_pos = ocr_text.find(target)\n",
    "        if target_pos != -1:\n",
    "            # Split the text into lines\n",
    "            lines = ocr_text.split(\"\\n\")\n",
    "            # Find the line containing the target string\n",
    "            for i, line in enumerate(lines):\n",
    "                if target in line:\n",
    "                    # Case 1: Text is on the same line to the right of the target\n",
    "                    extracted_text = line.split(target, 1)[-1].strip()\n",
    "                    if not extracted_text:\n",
    "                        # Case 2: If no text is found on the same line, check the next line\n",
    "                        if i + 1 < len(lines):\n",
    "                            extracted_text = lines[i + 1].strip()\n",
    "                    print(f\"Extracted '{field_name}': {extracted_text}\")\n",
    "                    break\n",
    "        else:\n",
    "            print(f\"'{target}' not found on page {page_num}\")\n",
    "\n",
    "    # Optional: Show the page with the larger boundary drawn\n",
    "    image.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759f319e",
   "metadata": {},
   "source": [
    "### Section 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01e506f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "# Helper function to convert points to pixels using DPI\n",
    "def points_to_pixels(points, dpi=300):\n",
    "    return (points / 72) * dpi\n",
    "\n",
    "# Step 1: Convert all pages of the PDF to images\n",
    "images = convert_from_path('Signed_TestFraudAffidavit.pdf', dpi=300)\n",
    "\n",
    "# Step 2: Define target strings for each page\n",
    "target_strings = {\n",
    "    1: [\n",
    "        {\"field_name\": \"Account Holder(s)\", \"target\": \"Account Holder(s)\", \"max_length\": 100},\n",
    "        {\"field_name\": \"Account Number\", \"target\": \"Account Number\", \"max_length\": 50},\n",
    "        {\"field_name\": \"Business Name\", \"target\": \"Business Name (if applicable)\", \"max_length\": 100},\n",
    "        {\"field_name\": \"Phone Number\", \"target\": \"Phone Number\", \"max_length\": 50},\n",
    "        {\"field_name\": \"Address\", \"target\": \"Address\", \"max_length\": 150},\n",
    "        {\"field_name\": \"City\", \"target\": \"City\", \"max_length\": 50},\n",
    "        {\"field_name\": \"State\", \"target\": \"State\", \"max_length\": 20},\n",
    "        {\"field_name\": \"Zip\", \"target\": \"Zip\", \"max_length\": 10},\n",
    "        {\"field_name\": \"Was a police report filed?\", \"target\": \"Was a police report filed?\", \"max_length\": 10},\n",
    "        {\"field_name\": \"Name of Law Enforcement Agency\", \"target\": \"Name of Law Enforcement Agency\", \"max_length\": 100},\n",
    "        {\"field_name\": \"Report Number\", \"target\": \"Report Number\", \"max_length\": 50}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Step 3: Loop through each page and process OCR\n",
    "for page_num, image in enumerate(images, start=1):\n",
    "    print(f\"Processing page {page_num}...\")\n",
    "\n",
    "    # Step 4: Perform OCR on the whole page\n",
    "    ocr_text = pytesseract.image_to_string(image)\n",
    "\n",
    "    # Step 5: Normalize OCR text\n",
    "    normalized_ocr_text = '\\n'.join([line.strip().lower() for line in ocr_text.split('\\n') if line.strip()])\n",
    "\n",
    "    # Debug: Print all OCR lines for context\n",
    "    print(\"OCR Text Lines:\")\n",
    "    for line in normalized_ocr_text.split('\\n'):\n",
    "        print(f\"  {line}\")\n",
    "\n",
    "    # Step 6: Search for each target string and extract its value\n",
    "    page_targets = target_strings.get(page_num, [])\n",
    "    for target in page_targets:\n",
    "        field_name = target[\"field_name\"]\n",
    "        target_text = target[\"target\"].lower().strip()\n",
    "        max_length = target[\"max_length\"]\n",
    "\n",
    "        print(f\"\\nSearching for '{target_text}'...\")\n",
    "\n",
    "        # Step 7: Find the line containing the target string\n",
    "        extracted_text = \"\"\n",
    "\n",
    "        lines = normalized_ocr_text.split(\"\\n\")\n",
    "        for i, line in enumerate(lines):\n",
    "            # Step 8: Use fuzzy matching\n",
    "            if fuzz.partial_ratio(line, target_text) > 85:\n",
    "                # Case 1: Text is on the same line, extract to the right\n",
    "                extracted_text = line.split(target_text, 1)[-1].strip()[:max_length]\n",
    "\n",
    "                # Case 2: If no text to the right, check the next line\n",
    "                if not extracted_text and i + 1 < len(lines):\n",
    "                    extracted_text = lines[i + 1].strip()[:max_length]\n",
    "\n",
    "                break  # Stop searching once the target is found\n",
    "\n",
    "        # Step 9: Output the extracted text\n",
    "        if extracted_text:\n",
    "            print(f\"Extracted '{field_name}': {extracted_text}\")\n",
    "        else:\n",
    "            print(f\"'{field_name}' not found on page {page_num}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d775e5cb",
   "metadata": {},
   "source": [
    "### Old section below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a765018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6736d935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47a65fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a50bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae759470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f589da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9805c3a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb5737f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea7ac36",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = py.image_to_string(image_1).encode(\"utf-8\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b480d0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert image to grayscale\n",
    "image_1 = cv2.imread('test_image.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Apply thresholding to improve contrast\n",
    "_, processed_image = cv2.threshold(image_1, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Save or process with pytesseract\n",
    "text = py.image_to_string(Image.fromarray(processed_image))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9311aebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "image = cv2.imread('test_image_2.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Apply thresholding\n",
    "_, thresh = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Apply dilation to enhance symbols\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "processed_image = cv2.dilate(thresh, kernel, iterations=1)\n",
    "\n",
    "# Save or use with pytesseract\n",
    "text = py.image_to_string(Image.fromarray(processed_image))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218a551d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('test_image.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Apply adaptive thresholding\n",
    "#processed_image = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "# Optional: Detect edges to enhance symbols\n",
    "#edges = cv2.Canny(processed_image, 100, 200)\n",
    "\n",
    "# Convert to PIL image for pytesseract\n",
    "#pil_image = Image.fromarray(edges)\n",
    "\n",
    "# Run pytesseract\n",
    "text = py.image_to_string(pil_image, config=\"--psm 6\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284648c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your image\n",
    "image = Image.open(\"test_image_4.png\")\n",
    "\n",
    "# Set custom Tesseract options\n",
    "custom_config = r'--oem 3 --psm 6'\n",
    "\n",
    "# Perform OCR\n",
    "text = py.image_to_string(image, config=custom_config)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea75e93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "\n",
    "filePath = '/Users/user1/Desktop/folder1/pdf1.pdf'\n",
    "doc = convert_from_path(filePath)\n",
    "path, fileName = os.path.split(filePath)\n",
    "fileBaseName, fileExtension = os.path.splitext(fileName)\n",
    "\n",
    "for page_number, page_data in enumerate(doc):\n",
    "    txt = pytesseract.image_to_string(Image.fromarray(page_data)).encode(\"utf-8\")\n",
    "    print(\"Page # {} - {}\".format(str(page_number),txt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4155f4dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
